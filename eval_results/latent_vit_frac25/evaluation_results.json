{
  "accuracy": 0.45723042630259125,
  "classification_report": {
    "Angry": {
      "precision": 0.3575240128068303,
      "recall": 0.3496868475991649,
      "f1-score": 0.35356200527704484,
      "support": 958.0
    },
    "Disgust": {
      "precision": 0.3375,
      "recall": 0.24324324324324326,
      "f1-score": 0.28272251308900526,
      "support": 111.0
    },
    "Fear": {
      "precision": 0.30980861244019137,
      "recall": 0.2529296875,
      "f1-score": 0.278494623655914,
      "support": 1024.0
    },
    "Happy": {
      "precision": 0.6498630136986301,
      "recall": 0.6685456595264938,
      "f1-score": 0.6590719644345652,
      "support": 1774.0
    },
    "Neutral": {
      "precision": 0.4158183241973375,
      "recall": 0.4306569343065693,
      "f1-score": 0.4231075697211155,
      "support": 1233.0
    },
    "Sad": {
      "precision": 0.3157894736842105,
      "recall": 0.3608660785886127,
      "f1-score": 0.33682634730538924,
      "support": 1247.0
    },
    "Surprise": {
      "precision": 0.6190476190476191,
      "recall": 0.5944645006016848,
      "f1-score": 0.6065070595457336,
      "support": 831.0
    },
    "accuracy": 0.45723042630259125,
    "macro avg": {
      "precision": 0.4293358651249742,
      "recall": 0.41434185019510983,
      "f1-score": 0.4200417261469668,
      "support": 7178.0
    },
    "weighted avg": {
      "precision": 0.4556970672272455,
      "recall": 0.45723042630259125,
      "f1-score": 0.4555848724682814,
      "support": 7178.0
    }
  },
  "model_config": {
    "latent_dim": 512,
    "seq_len": 18,
    "embed_dim": 512,
    "depth": 6,
    "heads": 8,
    "mlp_dim": 2048,
    "num_classes": 7,
    "dropout": 0.1
  },
  "checkpoint_path": "experiments/latent_vit_d6_h8_lr0.0001_bs64_ep60_frac25/latent_vit_d6_h8_lr0.0001_bs64_ep60_frac25_20251127_153503/checkpoints/best_model.pt",
  "test_dataset_size": 7178
}