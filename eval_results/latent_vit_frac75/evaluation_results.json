{
  "accuracy": 0.5320423516299805,
  "classification_report": {
    "Angry": {
      "precision": 0.42538071065989846,
      "recall": 0.4373695198329854,
      "f1-score": 0.43129181677817807,
      "support": 958.0
    },
    "Disgust": {
      "precision": 0.5,
      "recall": 0.4774774774774775,
      "f1-score": 0.48847926267281105,
      "support": 111.0
    },
    "Fear": {
      "precision": 0.41226215644820297,
      "recall": 0.380859375,
      "f1-score": 0.39593908629441626,
      "support": 1024.0
    },
    "Happy": {
      "precision": 0.6766683911019141,
      "recall": 0.7373167981961668,
      "f1-score": 0.7056919341785811,
      "support": 1774.0
    },
    "Neutral": {
      "precision": 0.47884187082405344,
      "recall": 0.5231143552311436,
      "f1-score": 0.5,
      "support": 1233.0
    },
    "Sad": {
      "precision": 0.41938405797101447,
      "recall": 0.37129109863672816,
      "f1-score": 0.39387494683113566,
      "support": 1247.0
    },
    "Surprise": {
      "precision": 0.714663143989432,
      "recall": 0.6510228640192539,
      "f1-score": 0.681360201511335,
      "support": 831.0
    },
    "accuracy": 0.5320423516299805,
    "macro avg": {
      "precision": 0.5181714758563594,
      "recall": 0.5112073554848221,
      "f1-score": 0.5138053211809225,
      "support": 7178.0
    },
    "weighted avg": {
      "precision": 0.5283992636529771,
      "recall": 0.5320423516299805,
      "f1-score": 0.5292017637758161,
      "support": 7178.0
    }
  },
  "model_config": {
    "latent_dim": 512,
    "seq_len": 18,
    "embed_dim": 512,
    "depth": 6,
    "heads": 8,
    "mlp_dim": 2048,
    "num_classes": 7,
    "dropout": 0.1
  },
  "checkpoint_path": "experiments/latent_vit_d6_h8_lr0.0001_bs64_ep60_frac75/latent_vit_d6_h8_lr0.0001_bs64_ep60_frac75_20251127_154524/checkpoints/best_model.pt",
  "test_dataset_size": 7178
}